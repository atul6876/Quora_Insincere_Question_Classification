{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pereparing the machine & importing the necessary modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the training and validation datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('train.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1225312\n",
       "1      80810\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see the number of insincere questions\n",
    "# We see that only about 6% of the total questions have been labeled insincere\n",
    "# As expected, this is an imbalanced classification problem\n",
    "\n",
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>363125</th>\n",
       "      <td>472cf5fdc5dc8218c6d8</td>\n",
       "      <td>Why are new vehicles so costly, considering le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285452</th>\n",
       "      <td>fbed5ed869a01957c90f</td>\n",
       "      <td>Is Trump's contemplating, suggestive remark ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636169</th>\n",
       "      <td>7c9a92b811724c828308</td>\n",
       "      <td>Are Iranians busy with producing atomic bombs ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460846</th>\n",
       "      <td>5a3f3f8f96a59560fe5c</td>\n",
       "      <td>What is Trump' s reaction to the fact that the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688968</th>\n",
       "      <td>86f25609f8aa68938fef</td>\n",
       "      <td>Are all the Quora users fucking dumb or is Quo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "363125   472cf5fdc5dc8218c6d8   \n",
       "1285452  fbed5ed869a01957c90f   \n",
       "636169   7c9a92b811724c828308   \n",
       "460846   5a3f3f8f96a59560fe5c   \n",
       "688968   86f25609f8aa68938fef   \n",
       "\n",
       "                                             question_text  target  \n",
       "363125   Why are new vehicles so costly, considering le...       1  \n",
       "1285452  Is Trump's contemplating, suggestive remark ab...       1  \n",
       "636169   Are Iranians busy with producing atomic bombs ...       1  \n",
       "460846   What is Trump' s reaction to the fact that the...       1  \n",
       "688968   Are all the Quora users fucking dumb or is Quo...       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing a sample of questions labeled as insincere\n",
    "\n",
    "data[data.target==1].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = data['question_text']\n",
    "trainDF['label'] = data['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'],\n",
    "                                                                      stratify=trainDF['label'], test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - transforming free form text into structured numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count-Vectorizer: Using a simple bag of words model\n",
    "\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-IDF: Using Term Frequency - Inverse Document Frequency to extract features\n",
    "## Better than a simple Bag-of-Words transformation, as we get higer weights for words that tend to distinguish the text\n",
    "\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the data is imbalanced, prediction accuracy is not going to be a good metric to evaluate model performances\n",
    "# Furthermore, it is much more important that we don't predict insincere questions as sincere than the other way around\n",
    "# Thus, Recall is the metric of interest\n",
    "\n",
    "# To avoid re-typing, here I'm writing a function that takes in the classifier (model), training set, training labels(target)\n",
    "# & validation set,and trains the classifier on the training set and the training labels, predicts the labels on the \n",
    "# validation set, and returns classification reports that show model performance.\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    return metrics.classification_report(valid_y, predictions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on the model trained on count vectors (Bag-of-Words)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96    245063\n",
      "           1       0.46      0.69      0.55     16162\n",
      "\n",
      "   micro avg       0.93      0.93      0.93    261225\n",
      "   macro avg       0.72      0.82      0.76    261225\n",
      "weighted avg       0.95      0.93      0.94    261225\n",
      "\n",
      "\n",
      "Classification Report on the model trained with TF-IDF vectors\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    245063\n",
      "           1       0.71      0.23      0.35     16162\n",
      "\n",
      "   micro avg       0.95      0.95      0.95    261225\n",
      "   macro avg       0.83      0.61      0.66    261225\n",
      "weighted avg       0.94      0.95      0.93    261225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The main advantae of Naive-Bayes Classifier is that it trains really fast\n",
    "\n",
    "# Naive Bayes on Count Vectors\n",
    "print('Classification Report on the model trained on count vectors (Bag-of-Words)')\n",
    "print()\n",
    "print(train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count))\n",
    "\n",
    "print()\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "print('Classification Report on the model trained with TF-IDF vectors')\n",
    "print()\n",
    "print(train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear (Logistic Regression) Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on the model trained on count vectors (Bag-of-Words)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    245063\n",
      "           1       0.70      0.46      0.55     16162\n",
      "\n",
      "   micro avg       0.95      0.95      0.95    261225\n",
      "   macro avg       0.83      0.72      0.76    261225\n",
      "weighted avg       0.95      0.95      0.95    261225\n",
      "\n",
      "\n",
      "Classification Report on the model trained with TF-IDF vectors\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    245063\n",
      "           1       0.70      0.40      0.51     16162\n",
      "\n",
      "   micro avg       0.95      0.95      0.95    261225\n",
      "   macro avg       0.83      0.70      0.74    261225\n",
      "weighted avg       0.95      0.95      0.95    261225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple linear model with a linear separation between categories, however trains slower than the NB classifier\n",
    "\n",
    "# Linear Classifier on Count Vectors\n",
    "print('Classification Report on the model trained on count vectors (Bag-of-Words)')\n",
    "print()\n",
    "print(train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count))\n",
    "\n",
    "print()\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "print('Classification Report on the model trained with TF-IDF vectors')\n",
    "print()\n",
    "print(train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on Recall scores on insincere questions (label=1), Naive-Bayes Model with TF-IDF performs the best (Recall = 0.71)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
